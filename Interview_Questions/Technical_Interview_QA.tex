\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[margin=1.8cm]{geometry}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{tcolorbox}

% Colors
\definecolor{questioncolor}{RGB}{0,102,204}
\definecolor{codebackground}{RGB}{245,245,245}

% Code style
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{codebackground},
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny\color{gray}
}
\lstset{style=mystyle}

% Custom boxes
\newtcolorbox{question}{
    colback=blue!5!white,
    colframe=questioncolor,
    fonttitle=\bfseries,
    title=Question,
    sharp corners
}

\newtcolorbox{answer}{
    colback=white,
    colframe=gray!50,
    fonttitle=\bfseries,
    title=Answer
}

% Header
\pagestyle{fancy}
\fancyhf{}
\rhead{DevSecOps Interview - INES TMIMI}
\lhead{\thepage}
\renewcommand{\headrulewidth}{0.4pt}

\titleformat{\section}
{\normalfont\Large\bfseries\color{questioncolor}}
{\thesection}{1em}{}

\begin{document}

\begin{titlepage}
    \centering
    \vspace*{2cm}
    {\Huge\bfseries Technical Interview Guide\par}
    \vspace{0.5cm}
    {\LARGE DevSecOps Engineer\par}
    \vspace{2cm}
    {\Large\bfseries INES TMIMI\par}
    \vspace{0.3cm}
    {\large Computer Engineering Student - ENSIT\par}
    \vspace{1.5cm}
    {\large \textbf{Coverage:}\par}
    {\large DevOps | Kubernetes | Security | CI/CD | MLOps\par}
    \vfill
    {\large \today\par}
\end{titlepage}

\tableofcontents
\newpage

\section{DevOps \& CI/CD}

\begin{question}
\textbf{Q1.1:} How did you achieve 62\% reduction in Jenkins pipeline build times at Elyadata?
\end{question}

\begin{answer}
\textbf{4 Key Optimizations:}

\textbf{1. Docker BuildKit (20\% improvement):}
\begin{lstlisting}[language=bash]
export DOCKER_BUILDKIT=1
# Multi-stage builds with layer caching
FROM maven:3.9-eclipse-temurin-17 AS builder
RUN mvn dependency:go-offline  # Cache dependencies
\end{lstlisting}

\textbf{2. Persistent Volume Caching (25\%):}
\begin{lstlisting}[language=yaml]
volumeMounts:
  - name: maven-cache
    mountPath: /root/.m2  # Shared across builds
\end{lstlisting}

\textbf{3. Parallel Execution (15\%):}
\begin{lstlisting}[language=groovy]
parallel {
    stage('Trivy') { agent { label 'security-1' } }
    stage('SonarQube') { agent { label 'security-2' } }
    stage('Snyk') { agent { label 'security-3' } }
}
\end{lstlisting}

\textbf{4. Gradle Optimization (10\%):}
\begin{lstlisting}
org.gradle.parallel=true
org.gradle.caching=true
\end{lstlisting}

\textbf{Result:} 18min â†’ 6.8min (62.2\% reduction)
\end{answer}

\begin{question}
\textbf{Q1.2:} Explain Jenkins dynamic Kubernetes agents vs static agents.
\end{question}

\begin{answer}
\textbf{Dynamic Kubernetes Agents Architecture:}
\begin{lstlisting}[language=yaml]
apiVersion: v1
kind: Pod
metadata:
  labels:
    jenkins: agent
spec:
  serviceAccountName: jenkins
  containers:
    - name: jnlp
      image: jenkins/inbound-agent:latest
    - name: maven
      image: maven:3.9-eclipse-temurin-17
      command: ['cat']
      tty: true
\end{lstlisting}

\textbf{Advantages:}
\begin{itemize}
    \item \textbf{Scalability:} Auto-scale based on build queue
    \item \textbf{Isolation:} Each build in separate pod
    \item \textbf{Cost:} Only pay during build execution
    \item \textbf{Consistency:} Fresh environment every time
\end{itemize}

\textbf{vs Static Agents:}
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Feature} & \textbf{Static} & \textbf{Dynamic K8s} \\
\hline
Resources & Always running & On-demand \\
Scaling & Manual & Automatic \\
Isolation & Shared & Complete \\
Cost & Fixed & Variable \\
\hline
\end{tabular}
\end{center}
\end{answer}

\begin{question}
\textbf{Q1.3:} Explain Docker multi-stage builds with example.
\end{question}

\begin{answer}
\textbf{Multi-Stage Build Benefits:}
\begin{itemize}
    \item Smaller images (build tools excluded)
    \item Better security (reduced attack surface)
    \item Faster deployments
\end{itemize}

\textbf{Example from Secure DevOps Project:}
\begin{lstlisting}[language=docker]
# Stage 1: Build
FROM maven:3.9-eclipse-temurin-17 AS builder
WORKDIR /build
COPY pom.xml .
RUN mvn dependency:go-offline
COPY src ./src
RUN mvn package -DskipTests

# Stage 2: Runtime
FROM eclipse-temurin:17-jre-alpine
RUN adduser -S appuser
WORKDIR /app
COPY --from=builder /build/target/*.jar app.jar
USER appuser
EXPOSE 8080
ENTRYPOINT ["java", "-jar", "app.jar"]
\end{lstlisting}

\textbf{Results:}
\begin{itemize}
    \item Single-stage: 850 MB
    \item Multi-stage: 285 MB
    \item Reduction: 66.5\%
\end{itemize}
\end{answer}

\newpage
\section{Kubernetes}

\begin{question}
\textbf{Q2.1:} Explain Kubernetes architecture and components.
\end{question}

\begin{answer}
\textbf{Control Plane:}
\begin{itemize}
    \item \textbf{API Server:} Front-end for K8s, exposes REST API
    \item \textbf{etcd:} Distributed key-value store for cluster state
    \item \textbf{Scheduler:} Assigns pods to nodes
    \item \textbf{Controller Manager:} Runs controllers (replication, endpoints, etc.)
\end{itemize}

\textbf{Node Components:}
\begin{itemize}
    \item \textbf{kubelet:} Agent ensuring containers run in pods
    \item \textbf{kube-proxy:} Network proxy for service communication
    \item \textbf{Container Runtime:} containerd, Docker, CRI-O
\end{itemize}

\textbf{My Deployment Methods:}
\begin{lstlisting}[language=yaml]
# 1. Direct kubectl
kubectl apply -f deployment.yaml

# 2. Helm Charts (staging)
helm install myapp ./chart --namespace staging

# 3. GitOps with Argo CD (production)
argocd app create myapp --repo https://github.com/...
\end{lstlisting}
\end{answer}

\begin{question}
\textbf{Q2.2:} How do you implement Blue-Green deployments?
\end{question}

\begin{answer}
\begin{lstlisting}[language=yaml]
# Blue deployment (current)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-blue
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: blue
---
# Green deployment (new)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-green
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: green
---
# Service (switch selector)
apiVersion: v1
kind: Service
metadata:
  name: myapp
spec:
  selector:
    app: myapp
    version: blue  # Change to 'green' for cutover
\end{lstlisting}

\textbf{Cutover Process:}
\begin{lstlisting}[language=bash]
# Deploy green
kubectl apply -f deployment-green.yaml
# Test green
kubectl port-forward deployment/app-green 8080:8080
# Switch traffic
kubectl patch svc myapp -p '{"spec":{"selector":{"version":"green"}}}'
# Rollback if needed
kubectl patch svc myapp -p '{"spec":{"selector":{"version":"blue"}}}'
\end{lstlisting}
\end{answer}

\newpage
\section{Security \& DevSecOps}

\begin{question}
\textbf{Q3.1:} Explain zero-trust security implementation with 25+ OPA policies.
\end{question}

\begin{answer}
\textbf{Zero-Trust Principles:}
\begin{itemize}
    \item Never trust, always verify
    \item Least privilege access
    \item Assume breach
    \item Microsegmentation
\end{itemize}

\textbf{1. RBAC - Least Privilege:}
\begin{lstlisting}[language=yaml]
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: app-role
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get"]
  resourceNames: ["app-secret"]  # Specific resources only
\end{lstlisting}

\textbf{2. Network Policies - Deny All by Default:}
\begin{lstlisting}[language=yaml]
# Default deny
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
spec:
  podSelector: {}
  policyTypes: [Ingress, Egress]
---
# Explicit allow
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-app-traffic
spec:
  podSelector:
    matchLabels:
      app: myapp
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
\end{lstlisting}

\textbf{3. OPA Policies (25+ rules):}
\begin{lstlisting}[language=rego]
package kubernetes.admission

# Deny privileged containers
deny[msg] {
  container := input.request.object.spec.containers[_]
  container.securityContext.privileged == true
  msg := "Privileged containers not allowed"
}

# Require resource limits
deny[msg] {
  container := input.request.object.spec.containers[_]
  not container.resources.limits
  msg := "Must specify resource limits"
}

# Block root users
deny[msg] {
  not input.request.object.spec.securityContext.runAsNonRoot
  msg := "Must not run as root"
}
\end{lstlisting}

\textbf{4. HashiCorp Vault - Dynamic Secrets:}
\begin{lstlisting}[language=bash]
# Dynamic DB credentials with 1h TTL
vault write database/roles/app-role \
  db_name=postgres \
  creation_statements="CREATE ROLE \"{{name}}\" ..." \
  default_ttl="1h" \
  max_ttl="24h"
\end{lstlisting}

\textbf{Results:}
\begin{itemize}
    \item 90\%+ vulnerability detection pre-production
    \item Zero hardcoded secrets
    \item 60\% faster remediation
    \item SOC 2 compliance
\end{itemize}
\end{answer}

\begin{question}
\textbf{Q3.2:} Walk through your multi-stage security scanning pipeline.
\end{question}

\begin{answer}
\textbf{13-Stage Security Pipeline:}

\textbf{Stage 1: Pre-Commit (Local):}
\begin{lstlisting}[language=bash]
# .git/hooks/pre-commit
gitleaks protect --staged
eslint src/
npm test -- --coverage
\end{lstlisting}

\textbf{Stage 2: Secret Scanning (Gitleaks):}
\begin{lstlisting}[language=groovy]
stage('Secret Scan') {
    sh 'gitleaks detect --exit-code=1'
}
\end{lstlisting}

\textbf{Stage 3-4: SAST (Parallel):}
\begin{lstlisting}[language=groovy]
parallel {
    stage('SonarQube') {
        sh 'mvn sonar:sonar -Dsonar.qualitygate.wait=true'
    }
    stage('Snyk Code') {
        sh 'snyk code test --severity-threshold=high'
    }
}
\end{lstlisting}

\textbf{Stage 5: SCA (Dependency Scan):}
\begin{lstlisting}[language=bash]
snyk test --severity-threshold=high
trivy fs --severity HIGH,CRITICAL .
\end{lstlisting}

\textbf{Stage 6-8: Container Security:}
\begin{lstlisting}[language=bash]
# Trivy image scan
trivy image --severity HIGH,CRITICAL ${IMAGE}

# Dockerfile linting
hadolint Dockerfile

# CIS compliance
trivy image --compliance docker-cis ${IMAGE}
\end{lstlisting}

\textbf{Stage 9-10: Policy Validation (OPA):}
\begin{lstlisting}[language=bash]
# Generate manifests
helm template myapp ./chart > manifests.yaml

# Test OPA policies
conftest test manifests.yaml --policy opa-policies/

# Policy coverage check
opa test opa-policies/ --coverage
\end{lstlisting}

\textbf{Stage 11: License Compliance:}
\begin{lstlisting}[language=rego]
forbidden_licenses = {"GPL-3.0", "AGPL-3.0"}
deny[msg] {
    dependency := input.dependencies[_]
    forbidden_licenses[dependency.license]
    msg := sprintf("Forbidden license: %v", [dependency.license])
}
\end{lstlisting}

\textbf{Stage 12: DAST (OWASP ZAP):}
\begin{lstlisting}[language=bash]
# Deploy to test env
kubectl apply -f k8s/test/

# Run ZAP scan
zap-baseline.py -t http://${TEST_URL} -r report.html
\end{lstlisting}

\textbf{Detection Rate: 90\%+ high/critical vulnerabilities}
\end{answer}

\newpage
\section{Infrastructure as Code}

\begin{question}
\textbf{Q4.1:} Explain your Terraform + Ansible architecture for AWS.
\end{question}

\begin{answer}
\textbf{Architecture:}
\begin{itemize}
    \item \textbf{Terraform:} Provision infrastructure (VPC, EKS, RDS, S3)
    \item \textbf{Ansible:} Configure applications and services
\end{itemize}

\textbf{Terraform Example - EKS Cluster:}
\begin{lstlisting}[language=hcl]
module "eks" {
  source  = "terraform-aws-modules/eks/aws"
  
  cluster_name    = "production-cluster"
  cluster_version = "1.28"
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets
  
  eks_managed_node_groups = {
    general = {
      desired_size = 3
      min_size     = 2
      max_size     = 10
      
      instance_types = ["t3.large"]
      capacity_type  = "ON_DEMAND"
    }
  }
}
\end{lstlisting}

\textbf{Ansible Playbook - Application Setup:}
\begin{lstlisting}[language=yaml]
- name: Configure Kubernetes cluster
  hosts: localhost
  tasks:
    - name: Install Helm
      shell: |
        curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
    
    - name: Deploy monitoring stack
      kubernetes.core.helm:
        name: prometheus
        chart_ref: prometheus-community/kube-prometheus-stack
        namespace: monitoring
\end{lstlisting}

\textbf{GitOps Workflow:}
\begin{enumerate}
    \item \textbf{Terraform:} terraform apply â†’ Infrastructure provisioned
    \item \textbf{Ansible:} ansible-playbook site.yml â†’ Services configured
    \item \textbf{Argo CD:} Continuous deployment of applications
\end{enumerate}
\end{answer}

\begin{question}
\textbf{Q4.2:} How do you manage Terraform state and secrets?
\end{question}

\begin{answer}
\textbf{Remote State with S3 + DynamoDB:}
\begin{lstlisting}[language=hcl]
terraform {
  backend "s3" {
    bucket         = "terraform-state-prod"
    key            = "eks/terraform.tfstate"
    region         = "us-east-1"
    dynamodb_table = "terraform-locks"  # State locking
    encrypt        = true
  }
}
\end{lstlisting}

\textbf{Secrets Management:}
\begin{lstlisting}[language=hcl]
# Store sensitive data in AWS Secrets Manager
resource "aws_secretsmanager_secret" "db_password" {
  name = "prod/db/password"
}

# Reference in resources
data "aws_secretsmanager_secret_version" "db_creds" {
  secret_id = aws_secretsmanager_secret.db_password.id
}

resource "aws_db_instance" "postgres" {
  password = data.aws_secretsmanager_secret_version.db_creds.secret_string
}
\end{lstlisting}

\textbf{Best Practices:}
\begin{itemize}
    \item Remote state with encryption
    \item State locking (prevent concurrent modifications)
    \item Never commit .tfstate files
    \item Use AWS Secrets Manager / Vault for sensitive data
    \item Workspace separation (dev, staging, prod)
\end{itemize}
\end{answer}

\newpage
\section{MLOps}

\begin{question}
\textbf{Q5.1:} Explain your MLOps pipeline for CallCenterAI with 86\% accuracy.
\end{question}

\begin{answer}
\textbf{Architecture:}

\textbf{1. Data Management (DVC):}
\begin{lstlisting}[language=bash]
# Track data versions
dvc add data/tickets.csv
dvc push

# Pipeline stages
dvc run -n preprocess \
  -d data/raw/ -o data/processed/ \
  python preprocess.py

dvc run -n train \
  -d data/processed/ -o models/ \
  -M metrics.json \
  python train.py
\end{lstlisting}

\textbf{2. Experiment Tracking (MLflow):}
\begin{lstlisting}[language=python]
import mlflow

with mlflow.start_run():
    # Train model
    model = train_model(X_train, y_train)
    
    # Log metrics
    mlflow.log_metric("accuracy", 0.86)
    mlflow.log_metric("f1_score", 0.84)
    
    # Log model
    mlflow.sklearn.log_model(model, "model")
    
    # Log parameters
    mlflow.log_params({
        "max_depth": 10,
        "n_estimators": 100
    })
\end{lstlisting}

\textbf{3. Model Architecture (Dual Approach):}
\begin{lstlisting}[language=python]
# Simple tickets â†’ TF-IDF + SVM
if ticket_complexity < threshold:
    prediction = svm_model.predict(tfidf_features)

# Complex tickets â†’ BERT
else:
    prediction = bert_model.predict(ticket_text)

# Intelligent router with LangChain + Groq LLM
router_decision = langchain_agent.select_model(ticket)
\end{lstlisting}

\textbf{4. Production Deployment:}
\begin{lstlisting}[language=python]
# FastAPI microservice
from fastapi import FastAPI
import mlflow.pyfunc

app = FastAPI()
model = mlflow.pyfunc.load_model("models:/ticket-classifier/production")

@app.post("/predict")
async def predict(ticket: Ticket):
    # PII scrubbing
    cleaned_text = remove_pii(ticket.text)
    
    # Prediction
    prediction = model.predict([cleaned_text])
    
    return {"category": prediction[0], "confidence": 0.86}
\end{lstlisting}

\textbf{5. CI/CD for ML:}
\begin{lstlisting}[language=yaml]
# GitHub Actions
name: ML Pipeline
on: [push]
jobs:
  train:
    runs-on: ubuntu-latest
    steps:
      - name: Train model
        run: |
          python train.py
          
      - name: Validate accuracy
        run: |
          accuracy=$(python evaluate.py)
          if [ $accuracy < 0.85 ]; then exit 1; fi
      
      - name: Deploy to production
        if: github.ref == 'refs/heads/main'
        run: |
          kubectl apply -f k8s/deployment.yaml
\end{lstlisting}

\textbf{Results:}
\begin{itemize}
    \item 86\% accuracy (TF-IDF+SVM baseline + BERT)
    \item Automated retraining pipeline
    \item A/B testing with Prometheus metrics
    \item Model versioning with MLflow
\end{itemize}
\end{answer}

\begin{question}
\textbf{Q5.2:} How do you monitor ML models in production?
\end{question}

\begin{answer}
\textbf{Monitoring Stack: Prometheus + Grafana}

\textbf{1. Custom Metrics:}
\begin{lstlisting}[language=python]
from prometheus_client import Counter, Histogram, Gauge

# Request metrics
prediction_requests = Counter('predictions_total', 'Total predictions')
prediction_latency = Histogram('prediction_latency_seconds', 'Prediction latency')
model_accuracy = Gauge('model_accuracy', 'Current model accuracy')

# In prediction endpoint
@prediction_latency.time()
def predict(data):
    prediction_requests.inc()
    result = model.predict(data)
    return result
\end{lstlisting}

\textbf{2. Data Drift Detection:}
\begin{lstlisting}[language=python]
from evidently import ColumnDriftMetric
from evidently.report import Report

# Compare training vs production data
report = Report(metrics=[
    ColumnDriftMetric(column_name='text_length'),
    ColumnDriftMetric(column_name='word_count')
])

report.run(reference_data=train_df, current_data=prod_df)

if report.as_dict()['metrics'][0]['result']['drift_detected']:
    trigger_retraining()
\end{lstlisting}

\textbf{3. Model Performance Monitoring:}
\begin{lstlisting}[language=python]
# Track prediction distribution
prediction_distribution = Counter(
    'prediction_categories', 
    'Distribution of predicted categories',
    ['category']
)

# Track confidence scores
confidence_scores = Histogram(
    'prediction_confidence',
    'Model confidence distribution'
)

# Alert on degradation
if current_accuracy < baseline_accuracy * 0.9:
    send_alert("Model accuracy degraded")
    trigger_retraining()
\end{lstlisting}

\textbf{4. Grafana Dashboard:}
\begin{itemize}
    \item Request rate and latency
    \item Prediction accuracy over time
    \item Data drift indicators
    \item Error rate by category
    \item Model resource usage (CPU, memory)
\end{itemize}
\end{answer}

\newpage
\section{Monitoring \& Observability}

\begin{question}
\textbf{Q6.1:} Explain your ELK stack setup for centralized logging.
\end{question}

\begin{answer}
\textbf{ELK Architecture:}

\textbf{1. Filebeat (Log Collection):}
\begin{lstlisting}[language=yaml]
# filebeat.yml
filebeat.inputs:
- type: container
  paths:
    - '/var/lib/docker/containers/*/*.log'
  processors:
    - add_kubernetes_metadata:
        host: ${NODE_NAME}
        matchers:
        - logs_path:
            logs_path: "/var/lib/docker/containers/"

output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "k8s-logs-%{+yyyy.MM.dd}"
\end{lstlisting}

\textbf{2. Logstash (Processing):}
\begin{lstlisting}[language=ruby]
input {
  beats {
    port => 5044
  }
}

filter {
  # Parse JSON logs
  json {
    source => "message"
  }
  
  # Add timestamp
  date {
    match => ["timestamp", "ISO8601"]
  }
  
  # Grok for custom patterns
  grok {
    match => { "message" => "%{LOGLEVEL:log_level} %{GREEDYDATA:log_message}" }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "app-logs-%{+YYYY.MM.dd}"
  }
}
\end{lstlisting}

\textbf{3. Elasticsearch (Storage):}
\begin{lstlisting}[language=yaml]
# Index template
{
  "index_patterns": ["app-logs-*"],
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 1,
    "index.lifecycle.name": "30-days-retention"
  }
}
\end{lstlisting}

\textbf{4. Kibana (Visualization):}
\begin{itemize}
    \item Dashboard for error rates
    \item Real-time log streaming
    \item Alert rules for critical errors
\end{itemize}
\end{answer}

\begin{question}
\textbf{Q6.2:} How do you implement Prometheus monitoring?
\end{question}

\begin{answer}
\textbf{Prometheus Setup:}

\textbf{1. ServiceMonitor for Application:}
\begin{lstlisting}[language=yaml]
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: app-metrics
spec:
  selector:
    matchLabels:
      app: myapp
  endpoints:
  - port: metrics
    interval: 30s
    path: /actuator/prometheus
\end{lstlisting}

\textbf{2. Custom Metrics in Application:}
\begin{lstlisting}[language=java]
@Component
public class MetricsConfig {
    private final Counter requestCounter;
    private final Timer requestTimer;
    
    public MetricsConfig(MeterRegistry registry) {
        this.requestCounter = Counter.builder("api_requests_total")
            .description("Total API requests")
            .tags("endpoint", "/api")
            .register(registry);
        
        this.requestTimer = Timer.builder("api_request_duration")
            .description("API request duration")
            .register(registry);
    }
}
\end{lstlisting}

\textbf{3. Alert Rules:}
\begin{lstlisting}[language=yaml]
groups:
- name: application-alerts
  rules:
  - alert: HighErrorRate
    expr: rate(http_requests_total{status="500"}[5m]) > 0.05
    for: 5m
    annotations:
      summary: "High error rate detected"
      
  - alert: HighMemoryUsage
    expr: container_memory_usage_bytes > 1073741824  # 1GB
    for: 5m
    annotations:
      summary: "High memory usage"
\end{lstlisting}

\textbf{4. Grafana Dashboard:}
\begin{itemize}
    \item Request rate, latency, errors (RED metrics)
    \item Resource usage (CPU, memory, disk)
    \item Custom business metrics
\end{itemize}
\end{answer}

\newpage
\section{GitOps \& Argo CD}

\begin{question}
\textbf{Q7.1:} Explain GitOps principles and your Argo CD implementation.
\end{question}

\begin{answer}
\textbf{GitOps Principles:}
\begin{enumerate}
    \item \textbf{Declarative:} Entire system described declaratively
    \item \textbf{Versioned:} Desired state stored in Git
    \item \textbf{Pulled Automatically:} Software agents pull desired state
    \item \textbf{Continuously Reconciled:} Agents ensure correct state
\end{enumerate}

\textbf{Repository Structure:}
\begin{lstlisting}[language=bash]
gitops-repo/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ app1/
â”‚   â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”‚   â””â”€â”€ service.yaml
â”‚   â”‚   â””â”€â”€ overlays/
â”‚   â”‚       â”œâ”€â”€ dev/
â”‚   â”‚       â”œâ”€â”€ staging/
â”‚   â”‚       â””â”€â”€ production/
â”‚   â””â”€â”€ app2/
â””â”€â”€ infrastructure/
    â”œâ”€â”€ namespaces/
    â””â”€â”€ ingress/
\end{lstlisting}

\textbf{Argo CD Application:}
\begin{lstlisting}[language=yaml]
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: myapp-prod
  namespace: argocd
spec:
  project: production
  source:
    repoURL: https://github.com/org/gitops-repo
    targetRevision: main
    path: apps/myapp/overlays/production
  destination:
    server: https://kubernetes.default.svc
    namespace: production
  syncPolicy:
    automated:
      prune: true      # Delete resources not in Git
      selfHeal: true   # Force sync on drift
    syncOptions:
      - CreateNamespace=true
\end{lstlisting}

\textbf{Deployment Workflow:}
\begin{enumerate}
    \item Developer commits code
    \item Jenkins builds \& tests
    \item Jenkins updates GitOps repo with new image tag
    \item Argo CD detects change
    \item Argo CD syncs to cluster
    \item Health checks validate deployment
\end{enumerate}

\textbf{Jenkins GitOps Update:}
\begin{lstlisting}[language=groovy]
stage('Update GitOps Repo') {
    steps {
        git clone https://github.com/org/gitops-repo
        cd gitops-repo
        yq eval -i '.image.tag = env(IMAGE_TAG)' apps/myapp/values.yaml
        git commit -m "Update image to ${IMAGE_TAG}"
        git push
    }
}
\end{lstlisting}
\end{answer}

\newpage
\section{Behavioral \& Architecture}

\begin{question}
\textbf{Q8.1:} Describe a challenging technical problem you solved at Elyadata.
\end{question}

\begin{answer}
\textbf{Problem:} Jenkins builds taking 18+ minutes, blocking rapid iteration

\textbf{Investigation:}
\begin{itemize}
    \item Analyzed pipeline execution times per stage
    \item Identified bottlenecks: dependency downloads (40\%), Docker builds (35\%), sequential security scans (25\%)
\end{itemize}

\textbf{Solution Implemented:}
\begin{enumerate}
    \item \textbf{Docker BuildKit:} Enabled parallel layer builds
    \item \textbf{Persistent Volumes:} Cached Maven deps across builds
    \item \textbf{Parallelization:} Ran security scans concurrently on separate agents
    \item \textbf{Gradle Tuning:} Enabled parallel project builds
\end{enumerate}

\textbf{Challenges Overcome:}
\begin{itemize}
    \item PVC permission issues â†’ Fixed with proper fsGroup
    \item Agent resource contention â†’ Configured pod priority classes
    \item Cache invalidation â†’ Implemented smart cache keys based on pom.xml hash
\end{itemize}

\textbf{Results:}
\begin{itemize}
    \item 62\% reduction in build time (18min â†’ 6.8min)
    \item 3x increase in deployment frequency
    \item Developer satisfaction improved
\end{itemize}

\textbf{Lessons Learned:}
\begin{itemize}
    \item Measure before optimizing
    \item Attack multiple bottlenecks in parallel
    \item Monitor impact of each change
\end{itemize}
\end{answer}

\begin{question}
\textbf{Q8.2:} How do you handle production incidents?
\end{question}

\begin{answer}
\textbf{Incident Response Process:}

\textbf{1. Detection (Automated):}
\begin{itemize}
    \item Prometheus alerts trigger PagerDuty
    \item Grafana dashboards show anomalies
    \item Log aggregation shows error spikes
\end{itemize}

\textbf{2. Initial Response (5 minutes):}
\begin{lstlisting}[language=bash]
# Check pod status
kubectl get pods -n production

# View recent logs
kubectl logs deployment/myapp -n production --tail=100

# Check metrics
curl http://prometheus/api/v1/query?query=up{job="myapp"}
\end{lstlisting}

\textbf{3. Mitigation:}
\begin{itemize}
    \item Rollback: \texttt{kubectl rollout undo deployment/myapp}
    \item Scale up: \texttt{kubectl scale deployment/myapp --replicas=10}
    \item Traffic reroute: Switch to blue deployment
\end{itemize}

\textbf{4. Root Cause Analysis:}
\begin{itemize}
    \item Analyze logs, metrics, traces
    \item Reproduce in staging environment
    \item Document findings
\end{itemize}

\textbf{5. Post-Incident:}
\begin{itemize}
    \item Write postmortem (blameless)
    \item Implement preventive measures
    \item Update runbooks
    \item Add monitoring/alerts if gaps found
\end{itemize}

\textbf{Example Incident:}
\begin{itemize}
    \item \textbf{Issue:} Memory leak causing OOMKilled
    \item \textbf{Detection:} Prometheus alert "High memory usage"
    \item \textbf{Mitigation:} Rollback to previous version
    \item \textbf{RCA:} Connection pool not properly closed
    \item \textbf{Fix:} Implement connection lifecycle management
    \item \textbf{Prevention:} Added memory leak testing in CI/CD
\end{itemize}
\end{answer}

\begin{question}
\textbf{Q8.3:} Why DevOps? What motivates you in this field?
\end{question}

\begin{answer}
\textbf{My DevOps Journey:}

\textbf{1. Problem-Solving at Scale:}
\begin{itemize}
    \item Fascinated by automating repetitive tasks
    \item Joy of reducing 18-minute builds to 6 minutes
    \item Impact: Helping entire teams move faster
\end{itemize}

\textbf{2. Intersection of Disciplines:}
\begin{itemize}
    \item Software development (writing code)
    \item System administration (infrastructure)
    \item Security (DevSecOps practices)
    \item Machine Learning (MLOps pipelines)
\end{itemize}

\textbf{3. Continuous Learning:}
\begin{itemize}
    \item Cloud-native technologies evolving rapidly
    \item New tools: Argo CD, OPA, Falco, etc.
    \item Earned 6 certifications (Oracle Cloud DevOps, GitHub Security, etc.)
\end{itemize}

\textbf{4. Business Impact:}
\begin{itemize}
    \item Enable faster time-to-market
    \item Improve reliability and security
    \item Reduce operational costs
    \item Measurable results (62\% faster builds, 90\% vuln detection)
\end{itemize}

\textbf{5. Future Vision:}
\begin{itemize}
    \item AI-powered DevOps (automated incident response)
    \item Platform engineering (internal developer platforms)
    \item FinOps (cost optimization in cloud)
\end{itemize}

\textbf{What I Love:}
\begin{itemize}
    \item Building robust, scalable systems
    \item Solving complex technical challenges
    \item Empowering developers with great tools
    \item Seeing deployments succeed smoothly
\end{itemize}
\end{answer}

\newpage
\section{Advanced Concepts}

\begin{question}
\textbf{Q9.1:} Explain service mesh (Istio) and when to use it.
\end{question}

\begin{answer}
\textbf{Service Mesh Concept:}
\begin{itemize}
    \item Dedicated infrastructure layer for service-to-service communication
    \item Sidecar proxy (Envoy) injected into each pod
    \item Control plane manages configuration
\end{itemize}

\textbf{Istio Architecture:}
\begin{lstlisting}[language=yaml]
# Enable Istio injection
apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    istio-injection: enabled
---
# Virtual Service (traffic routing)
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp
spec:
  hosts:
  - myapp
  http:
  - match:
    - headers:
        version:
          exact: canary
    route:
    - destination:
        host: myapp
        subset: v2
      weight: 10  # 10% traffic to canary
  - route:
    - destination:
        host: myapp
        subset: v1
      weight: 90  # 90% to stable
\end{lstlisting}

\textbf{Use Cases:}
\begin{enumerate}
    \item \textbf{Traffic Management:} Canary, A/B testing
    \item \textbf{Security:} mTLS between services
    \item \textbf{Observability:} Distributed tracing
    \item \textbf{Resilience:} Circuit breakers, retries
\end{enumerate}

\textbf{When NOT to Use:}
\begin{itemize}
    \item Small deployments (<10 services)
    \item Performance-critical apps (proxy adds latency)
    \item Team lacks expertise (complex to operate)
\end{itemize}
\end{answer}

\begin{question}
\textbf{Q9.2:} Explain your approach to disaster recovery.
\end{question}

\begin{answer}
\textbf{Disaster Recovery Strategy:}

\textbf{1. Backup Strategy (3-2-1 Rule):}
\begin{itemize}
    \item 3 copies of data
    \item 2 different media types
    \item 1 offsite copy
\end{itemize}

\textbf{2. Kubernetes Backup (Velero):}
\begin{lstlisting}[language=bash]
# Install Velero
velero install \
  --provider aws \
  --bucket k8s-backups \
  --backup-location-config region=us-east-1

# Schedule daily backups
velero schedule create daily-backup \
  --schedule="0 2 * * *" \
  --include-namespaces production

# Restore from backup
velero restore create --from-backup daily-backup-20250115
\end{lstlisting}

\textbf{3. Database Backups:}
\begin{lstlisting}[language=bash]
# Automated PostgreSQL backups
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgres-backup
spec:
  schedule: "0 2 * * *"  # Daily at 2 AM
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: postgres:15
            command:
            - /bin/bash
            - -c
            - |
              pg_dump -h $DB_HOST -U $DB_USER $DB_NAME | \
              gzip > /backup/db-$(date +%Y%m%d).sql.gz
              aws s3 cp /backup/*.sql.gz s3://db-backups/
\end{lstlisting}

\textbf{4. RTO/RPO Targets:}
\begin{itemize}
    \item \textbf{RTO (Recovery Time Objective):} 1 hour
    \item \textbf{RPO (Recovery Point Objective):} 15 minutes
\end{itemize}

\textbf{5. Multi-Region Deployment:}
\begin{lstlisting}[language=hcl]
# Terraform multi-region
module "eks_us_east" {
  source = "./eks"
  region = "us-east-1"
}

module "eks_eu_west" {
  source = "./eks"
  region = "eu-west-1"
}

# Route53 failover
resource "aws_route53_health_check" "primary" {
  fqdn = "app.us-east-1.example.com"
  type = "HTTPS"
}
\end{lstlisting}

\textbf{6. DR Testing:}
\begin{itemize}
    \item Quarterly DR drills
    \item Document recovery procedures
    \item Measure actual RTO/RPO
    \item Update runbooks based on findings
\end{itemize}
\end{answer}

\newpage
\section{Quick Fire Questions}

\begin{question}
\textbf{Q10.1:} Difference between Docker and containerd?
\end{question}

\begin{answer}
\begin{itemize}
    \item \textbf{Docker:} Complete container platform (CLI, API, registry)
    \item \textbf{containerd:} Container runtime (just runs containers)
    \item \textbf{Kubernetes:} Uses containerd directly (not Docker)
    \item \textbf{CRI:} Container Runtime Interface (standard)
\end{itemize}
\end{answer}

\begin{question}
\textbf{Q10.2:} What is a headless service in Kubernetes?
\end{question}

\begin{answer}
\begin{lstlisting}[language=yaml]
apiVersion: v1
kind: Service
metadata:
  name: myapp-headless
spec:
  clusterIP: None  # Headless
  selector:
    app: myapp
\end{lstlisting}

\begin{itemize}
    \item No cluster IP assigned
    \item Returns pod IPs directly (DNS A records)
    \item Use case: StatefulSets, databases
\end{itemize}
\end{answer}

\begin{question}
\textbf{Q10.3:} Explain Pod Disruption Budget.
\end{question}

\begin{answer}
\begin{lstlisting}[language=yaml]
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: myapp-pdb
spec:
  minAvailable: 2  # At least 2 pods always running
  selector:
    matchLabels:
      app: myapp
\end{lstlisting}

\begin{itemize}
    \item Limits voluntary disruptions (node drains, updates)
    \item Ensures minimum availability during maintenance
\end{itemize}
\end{answer}

\begin{question}
\textbf{Q10.4:} What is GitOps vs DevOps?
\end{question}

\begin{answer}
\begin{itemize}
    \item \textbf{DevOps:} Culture + practices (CI/CD, automation)
    \item \textbf{GitOps:} Specific implementation of DevOps
    \item \textbf{Key difference:} Git as single source of truth
    \item \textbf{GitOps principle:} Pull-based deployments (Argo CD)
    \item \textbf{DevOps can use:} Push-based (Jenkins, GitLab CI)
\end{itemize}
\end{answer}

\begin{question}
\textbf{Q10.5:} What are Init Containers?
\end{question}

\begin{answer}
\begin{lstlisting}[language=yaml]
spec:
  initContainers:
  - name: wait-for-db
    image: busybox
    command: ['sh', '-c', 'until nc -z postgres 5432; do sleep 1; done']
  containers:
  - name: app
    image: myapp:latest
\end{lstlisting}

\begin{itemize}
    \item Run before main containers
    \item Must complete successfully
    \item Use cases: DB migrations, config downloads, wait for dependencies
\end{itemize}
\end{answer}

\begin{question}
\textbf{Q10.6:} Explain HPA vs VPA vs Cluster Autoscaler.
\end{question}

\begin{answer}
\begin{itemize}
    \item \textbf{HPA (Horizontal Pod Autoscaler):} Add/remove pods based on CPU/memory
    \item \textbf{VPA (Vertical Pod Autoscaler):} Adjust pod resource requests/limits
    \item \textbf{Cluster Autoscaler:} Add/remove nodes based on pending pods
\end{itemize}

\textbf{Combined Usage:}
\begin{lstlisting}[language=yaml]
# HPA - scale pods
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
\end{lstlisting}
\end{answer}

\newpage
\section{Certifications \& Learning}

\begin{question}
\textbf{Q11.1:} Tell me about your Oracle Cloud DevOps Professional certification.
\end{question}

\begin{answer}
\textbf{Certification Overview:}
\begin{itemize}
    \item \textbf{Level:} Professional (advanced)
    \item \textbf{Topics:} OCI DevOps service, CI/CD, IaC, container orchestration
\end{itemize}

\textbf{Key Skills Learned:}
\begin{enumerate}
    \item \textbf{OCI DevOps Service:}
    \begin{itemize}
        \item Build pipelines, deployment pipelines
        \item Artifact repositories
        \item Blue-green and canary deployments
    \end{itemize}
    
    \item \textbf{Infrastructure as Code:}
    \begin{itemize}
        \item Terraform with OCI provider
        \item Resource Manager
        \item Stack management
    \end{itemize}
    
    \item \textbf{Container Services:}
    \begin{itemize}
        \item OKE (Oracle Kubernetes Engine)
        \item Container Registry
        \item Container Instances
    \end{itemize}
    
    \item \textbf{Monitoring \& Logging:}
    \begin{itemize}
        \item OCI Logging
        \item Application Performance Monitoring
        \item Notifications and alarms
    \end{itemize}
\end{enumerate}

\textbf{Real-World Application:}
\begin{itemize}
    \item Applied OCI knowledge to multi-cloud strategies
    \item Implemented similar patterns on AWS/Azure
    \item Understanding of cloud-agnostic DevOps practices
\end{itemize}
\end{answer}

\begin{question}
\textbf{Q11.2:} How do you stay updated with DevOps trends?
\end{question}

\begin{answer}
\textbf{Learning Resources:}

\textbf{1. Hands-On Practice:}
\begin{itemize}
    \item Personal projects (DevSecOps pipeline, MLOps platform)
    \item Home lab with K3s cluster
    \item Experimentation with new tools
\end{itemize}

\textbf{2. Certifications:}
\begin{itemize}
    \item Oracle Cloud DevOps Professional
    \item GitHub Advanced Security
    \item Aviatrix Multicloud Network Associate
    \item DataCamp: Data Scientist, Data Analyst, SQL Associate
\end{itemize}

\textbf{3. Online Communities:}
\begin{itemize}
    \item CNCF Slack channels
    \item Reddit: r/devops, r/kubernetes
    \item Stack Overflow
    \item GitHub discussions
\end{itemize}

\textbf{4. Conferences \& Webinars:}
\begin{itemize}
    \item KubeCon (watching recordings)
    \item DevOps Days
    \item Cloud Native Computing Foundation webinars
\end{itemize}

\textbf{5. Blogs \& Newsletters:}
\begin{itemize}
    \item Kubernetes Blog
    \item AWS DevOps Blog
    \item CNCF blog
    \item DevOps Weekly newsletter
\end{itemize}

\textbf{6. Documentation:}
\begin{itemize}
    \item Official docs (Kubernetes, Docker, Terraform)
    \item Tool-specific guides
    \item Best practice whitepapers
\end{itemize}

\textbf{Recent Technologies Explored:}
\begin{itemize}
    \item Argo Rollouts (progressive delivery)
    \item Crossplane (K8s-native IaC)
    \item Cilium (eBPF-based networking)
    \item OpenTelemetry (observability standard)
\end{itemize}
\end{answer}

\section{Final Tips}

\textbf{Technical Interview Preparation:}
\begin{enumerate}
    \item \textbf{Know Your Projects:} Be ready to deep-dive into any project
    \item \textbf{Metrics Matter:} Quantify your achievements (62\% reduction, 90\% detection)
    \item \textbf{Understand Trade-offs:} Every technical decision has pros/cons
    \item \textbf{Ask Clarifying Questions:} Shows thoughtful approach
    \item \textbf{Explain Your Thinking:} Walk through your problem-solving process
\end{enumerate}

\textbf{Key Talking Points:}
\begin{itemize}
    \item Pipeline optimization (62\% build time reduction)
    \item Zero-trust security (25+ OPA policies, 90\% vulnerability detection)
    \item Kubernetes expertise (dynamic agents, RBAC, network policies)
    \item MLOps experience (86\% accuracy, automated retraining)
    \item Production experience at Elyadata
\end{itemize}

\textbf{Questions to Ask Interviewer:}
\begin{itemize}
    \item What is your current CI/CD maturity level?
    \item How do you handle incidents and postmortems?
    \item What monitoring and observability tools do you use?
    \item How is your team structured? (Platform team, SRE, DevOps?)
    \item What are the biggest technical challenges right now?
    \item How do you approach security in the SDLC?
\end{itemize}

\vfill
\centering
\textbf{Good luck with your interview! ðŸš€}

\end{document}
